{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, val_loader_len, model, criterion, nb_classes, args, labels=None):\n",
    "    bar = Bar('Processing', max=val_loader_len)\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    ground_truth = np.empty((0, 0))\n",
    "    predicted = np.empty((0, 0))\n",
    "    for i, (inputs, target) in enumerate(val_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if nb_classes > 2:\n",
    "            target = target.cuda(non_blocking=True).to(dtype=torch.long)\n",
    "        else:\n",
    "            target = target.cuda(non_blocking=True).to(dtype=torch.float)\n",
    "            target = torch.unsqueeze(target, 1)\n",
    "\n",
    "        inputs = inputs.cuda(non_blocking=True).to(dtype=torch.float)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # compute output\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        if nb_classes > 2:\n",
    "            prec1 = accuracy(output, target, topk=(1,))\n",
    "        else:\n",
    "            prec1 = binary_acc(output, target)\n",
    "\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        y_pred = output.argmax(dim=1).cpu()\n",
    "        predicted = np.append(predicted, y_pred)\n",
    "        ground_truth = np.append(ground_truth, target.cpu())\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix = '({batch}/{size}) Data: {data:.3f}s | Dataset: {dt:} | Batch: {bt:.3f}s | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "            batch=i + 1,\n",
    "            dt=args.dataset,\n",
    "            size=val_loader_len,\n",
    "            data=data_time.avg,\n",
    "            bt=batch_time.avg,\n",
    "            total=bar.elapsed_td,\n",
    "            eta=bar.eta_td,\n",
    "            loss=losses.avg,\n",
    "            top1=top1.avg\n",
    "        )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "\n",
    "    res = None\n",
    "    if labels is not None:\n",
    "        ground_truth = ground_truth.astype('int')\n",
    "        predicted = predicted.astype('int')\n",
    "        res = classification_report(\n",
    "            ground_truth, predicted, target_names=labels)\n",
    "\n",
    "    return (losses.avg, top1.avg, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib\n",
    "import time\n",
    "import shutil\n",
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tensorboardX import SummaryWriter\n",
    "import numpy as np\n",
    "from math import cos, pi\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from model.net import get_network\n",
    "from model.config import config\n",
    "from utils import Bar, Logger, AverageMeter, accuracy, mkdir_p, savefig, argparser, binary_acc\n",
    "from UCR_DataLoader.UCR_Archive_Dataset import UCR_DataSet\n",
    "from UCR_DataLoader.UCR_Archive_Dataset import get_data\n",
    "import random\n",
    "from skimage.util.shape import view_as_windows\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, train_loader_len, model, criterion, optimizer, epoch, args, nb_classes):\n",
    "    bar = Bar('Processing', max=train_loader_len)\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        c_lr = adjust_learning_rate(\n",
    "            optimizer, epoch, i, train_loader_len, args)\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if nb_classes > 2:\n",
    "            target = target.cuda(non_blocking=True).to(dtype=torch.long)\n",
    "            #target = target.to(dtype=torch.long)\n",
    "        else:\n",
    "            target = target.cuda(non_blocking=True).to(dtype=torch.float)\n",
    "            target = torch.unsqueeze(target, 1)\n",
    "\n",
    "        inputs = inputs.cuda(non_blocking=True).to(dtype=torch.float)\n",
    "        #inputs = inputs.to(dtype=torch.float)\n",
    "\n",
    "        # compute output\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        if nb_classes > 2:\n",
    "            prec1 = accuracy(output, target, topk=(1,))\n",
    "        else:\n",
    "            prec1 = binary_acc(output, target)\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if args.clip_grad:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # plot progress\n",
    "        bar.suffix = '({batch}/{size}) | Config: {mc:} | Dataset: {dt:} | lr: {lr: .5f} | Total: {total:} | ETA: {eta:} | Loss: {loss:.4f} | top1: {top1: .4f}'.format(\n",
    "            batch=i + 1,\n",
    "            mc=args.model_configuration,\n",
    "            dt=args.dataset,\n",
    "            size=train_loader_len,\n",
    "            total=bar.elapsed_td,\n",
    "            eta=bar.eta_td,\n",
    "            loss=losses.avg,\n",
    "            top1=top1.avg,\n",
    "            lr=c_lr\n",
    "        )\n",
    "        bar.next()\n",
    "    bar.finish()\n",
    "    return (losses.avg, top1.avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, checkpoint='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    filepath = os.path.join(checkpoint, filename)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(\n",
    "            checkpoint, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, iteration, num_iter, args):\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    '''\n",
    "    warmup_epoch = 5 if args.warmup else 0\n",
    "    warmup_iter = warmup_epoch * num_iter\n",
    "    current_iter = iteration + epoch * num_iter\n",
    "    max_iter = args.epochs * num_iter\n",
    "\n",
    "    if args.lr_decay == 'step':\n",
    "        lr = args.lr * \\\n",
    "            (args.gamma ** ((current_iter - warmup_iter) // (max_iter - warmup_iter)))\n",
    "    elif args.lr_decay == 'cos':\n",
    "        lr = args.lr * \\\n",
    "            (1 + cos(pi * (current_iter - warmup_iter) / (max_iter - warmup_iter))) / 2\n",
    "    elif args.lr_decay == 'linear':\n",
    "        lr = args.lr * (1 - (current_iter - warmup_iter) / \\\n",
    "                        (max_iter - warmup_iter))\n",
    "    elif args.lr_decay == 'schedule':\n",
    "        count = sum([1 for s in args.schedule if s <= epoch])\n",
    "        lr = args.lr * pow(args.gamma, count)\n",
    "    else:\n",
    "        raise ValueError('Unknown lr mode {}'.format(args.lr_decay))\n",
    "\n",
    "    if epoch < warmup_epoch:\n",
    "        lr = args.lr * current_iter / warmup_iter\n",
    "\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    '''\n",
    "    return lr\n",
    "\n",
    "\n",
    "def convert_atcn1d_to2d(model_1d, model_2d):\n",
    "    atcn1d_state = model_1d.state_dict()\n",
    "    atcn2d_state = model_2d.state_dict()\n",
    "    for (ent_1d_key, ent_1d_val), (ent_2d_key, ent_2d_val) in zip(atcn1d_state.items(), atcn2d_state.items()):\n",
    "        assert(ent_1d_key == ent_2d_key)\n",
    "        if len(ent_2d_val.shape) == 4:\n",
    "            new_val = ent_2d_val.squeeze(2)\n",
    "        else:\n",
    "            new_val = ent_2d_val\n",
    "        assert(ent_1d_val.shape == new_val.shape)\n",
    "        atcn1d_state[ent_1d_key] = new_val\n",
    "        pass\n",
    "    model_1d.load_state_dict(atcn1d_state)\n",
    "\n",
    "\n",
    "def extend_4d(x, y):\n",
    "\n",
    "    x = x.reshape(x.shape[1], x.shape[0])\n",
    "    # This function is for making a 1D input time series to 4D.\n",
    "    x = torch.unsqueeze(x, 0)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('args.pkl', 'rb') as f:\n",
    "    args = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'view_as_windows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#X35sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Loop on keys of dictionary ground_truth\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#X35sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m ground_truth:\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#X35sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39m# Remeber to set the desired time window\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#X35sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     activity[k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmoveaxis(view_as_windows(activity[k], (\u001b[39m4\u001b[39m\u001b[39m*\u001b[39mcf\u001b[39m.\u001b[39mtime_window,\u001b[39m1\u001b[39m),\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)[:,\u001b[39m0\u001b[39m,:,:],\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#X35sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     activity[k] \u001b[39m=\u001b[39m activity[k][:,:,\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#X35sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     sig[k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((ppg[k],acc[k]),axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'view_as_windows' is not defined"
     ]
    }
   ],
   "source": [
    "# Sampling frequency of both ppg and acceleration data in IEEE_Training dataset\n",
    "fs_IEEE_Training = 125\n",
    "# Sampling frequency of acceleration data in PPG_Dalia dataset\n",
    "# The sampling frequency of ppg data in PPG_Dalia dataset is fs_PPG_Dalia*2\n",
    "fs_PPG_Dalia = 32\n",
    "\n",
    "fs_activity = 4\n",
    "\n",
    "Sessioni = dict()\n",
    "S = dict()\n",
    "acc = dict()\n",
    "ppg = dict()\n",
    "activity = dict()\n",
    "\n",
    "random.seed(20)\n",
    "    \n",
    "ground_truth = dict()\n",
    "\n",
    "val = dataset\n",
    "    \n",
    "numbers= list(range(1,16))\n",
    "session_list=random.sample(numbers,len(numbers))\n",
    "for j in session_list:\n",
    "    paz = j\n",
    "    \n",
    "    with open('/media/segate/Bits/4-1/SOP_Kamlesh_sir/data/qppg/data/' + 'PPG_FieldStudy/S' + str(j) +'/S' + str(j) +'.pkl', 'rb') as f:\n",
    "        S[paz] = pickle.load(f, encoding='latin1')\n",
    "    ppg[paz] = S[paz]['signal']['wrist']['BVP'][::2]\n",
    "    acc[paz] = S[paz]['signal']['wrist']['ACC']\n",
    "    activity[paz] = S[paz]['activity']\n",
    "    ground_truth[paz] = S[paz]['label']\n",
    "    \n",
    "sig = dict()\n",
    "act_list = []\n",
    "groups= []\n",
    "sig_list = []\n",
    "ground_truth_list = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(cf.path_PPG_Dalia+'slimmed_dalia.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop on keys of dictionary ground_truth\n",
    "for k in ground_truth:\n",
    "    # Remeber to set the desired time window\n",
    "    activity[k] = np.moveaxis(view_as_windows(activity[k], (4*0.5,1),4*2)[:,0,:,:],1,2)\n",
    "    activity[k] = activity[k][:,:,0]\n",
    "    sig[k] = np.concatenate((ppg[k],acc[k]),axis=1)\n",
    "    sig[k]= np.moveaxis(view_as_windows(sig[k], (fs_PPG_Dalia*0.5,4),fs_PPG_Dalia*2)[:,0,:,:],1,2)\n",
    "    groups.append(np.full(sig[k].shape[0],k))\n",
    "    sig_list.append(sig[k])\n",
    "    act_list.append(activity[k])\n",
    "    ground_truth[k] = np.reshape(ground_truth[k], (ground_truth[k].shape[0],1))\n",
    "    ground_truth_list.append(ground_truth[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"gruppo\",groups)\n",
    "groups = np.hstack(groups)\n",
    "X = np.vstack(sig_list)\n",
    "y = np.reshape(np.vstack(ground_truth_list),(-1,1))\n",
    "\n",
    "act = np.vstack(act_list)\n",
    "\n",
    "data = dict()\n",
    "data['X'] = X\n",
    "data['y'] = y\n",
    "data['groups'] = groups\n",
    "data['act'] = act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64747, 4, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64697, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X2.pkl', 'wb') as f:\n",
    "    pickle.dump(X, f)\n",
    "\n",
    "with open('y2.pkl', 'wb') as f:\n",
    "    pickle.dump(data['act'], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PPGDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        f1 = open('X2.pkl', 'rb')\n",
    "        f2 = open('y2.pkl', 'rb')\n",
    "\n",
    "        self.x = torch.from_numpy(pickle.load(f1))\n",
    "        self.y = torch.from_numpy(pickle.load(f2).reshape(-1))\n",
    "        f1.close()\n",
    "        f2.close()\n",
    "        self.n_samples = self.x.shape[0]\n",
    "        self.length = self.x.shape[1]*self.x.shape[2]\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        tmp_x = self.x[index]\n",
    "        tmp_y = self.y[index]\n",
    "\n",
    "        tmp_x, tmp_y = extend_4d(tmp_x, tmp_y)\n",
    "\n",
    "        return tmp_x,tmp_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = PPGDataset()\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset,batch_size=1024, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter2 = iter(dataloader)\n",
    "data2 = dataiter2.next()\n",
    "feat,lab = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: [1 | 150]\n",
      "2.041975245743915 tensor(25.3865, device='cuda:0')\n",
      "\n",
      "Epoch: [2 | 150]\n",
      "2.004748555436209 tensor(26.9047, device='cuda:0')\n",
      "\n",
      "Epoch: [3 | 150]\n",
      "2.0016321423968906 tensor(27.0623, device='cuda:0')\n",
      "\n",
      "Epoch: [4 | 150]\n",
      "1.9999967190500063 tensor(27.0669, device='cuda:0')\n",
      "\n",
      "Epoch: [5 | 150]\n",
      "1.9998559097154707 tensor(27.0823, device='cuda:0')\n",
      "\n",
      "Epoch: [6 | 150]\n",
      "1.9998172385787563 tensor(27.0808, device='cuda:0')\n",
      "\n",
      "Epoch: [7 | 150]\n",
      "1.999025362501631 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [8 | 150]\n",
      "1.9979054185030187 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [9 | 150]\n",
      "1.9989475297849055 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [10 | 150]\n",
      "1.9983592970239752 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [11 | 150]\n",
      "1.9971302115952372 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [12 | 150]\n",
      "2.000212572161394 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [13 | 150]\n",
      "1.9979183601832642 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [14 | 150]\n",
      "1.9985792192342775 tensor(27.0854, device='cuda:0')\n",
      "\n",
      "Epoch: [15 | 150]\n",
      "1.9985433040918017 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [16 | 150]\n",
      "2.0018097352235533 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [17 | 150]\n",
      "1.9986060295686492 tensor(27.0839, device='cuda:0')\n",
      "\n",
      "Epoch: [18 | 150]\n",
      "1.998340705287008 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [19 | 150]\n",
      "1.9978161110576704 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [20 | 150]\n",
      "2.0001878921874456 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [21 | 150]\n",
      "1.9987564397443334 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [22 | 150]\n",
      "1.9980044108419428 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [23 | 150]\n",
      "1.9984891627332608 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [24 | 150]\n",
      "1.9977781737999805 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [25 | 150]\n",
      "1.9984006387989632 tensor(27.0669, device='cuda:0')\n",
      "\n",
      "Epoch: [26 | 150]\n",
      "1.9977628068688136 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [27 | 150]\n",
      "1.999071707653278 tensor(27.0870, device='cuda:0')\n",
      "\n",
      "Epoch: [28 | 150]\n",
      "1.9974010224850285 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [29 | 150]\n",
      "1.9970706137314371 tensor(27.1086, device='cuda:0')\n",
      "\n",
      "Epoch: [30 | 150]\n",
      "1.9975867687634932 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [31 | 150]\n",
      "1.9983816784332236 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [32 | 150]\n",
      "1.997290887525095 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [33 | 150]\n",
      "1.999034214106678 tensor(27.0638, device='cuda:0')\n",
      "\n",
      "Epoch: [34 | 150]\n",
      "1.9973430303978104 tensor(27.0901, device='cuda:0')\n",
      "\n",
      "Epoch: [35 | 150]\n",
      "1.9983759047263454 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [36 | 150]\n",
      "1.99876832074231 tensor(27.0854, device='cuda:0')\n",
      "\n",
      "Epoch: [37 | 150]\n",
      "1.9985118618927928 tensor(27.0808, device='cuda:0')\n",
      "\n",
      "Epoch: [38 | 150]\n",
      "1.9977666351133005 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [39 | 150]\n",
      "1.998220190441518 tensor(27.0870, device='cuda:0')\n",
      "\n",
      "Epoch: [40 | 150]\n",
      "1.9966906190318048 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [41 | 150]\n",
      "1.9986625091374894 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [42 | 150]\n",
      "1.9982170539485782 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [43 | 150]\n",
      "1.998370315698402 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [44 | 150]\n",
      "1.9989538792707926 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [45 | 150]\n",
      "1.999918501288767 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [46 | 150]\n",
      "1.999242511368487 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [47 | 150]\n",
      "1.9983338398412511 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [48 | 150]\n",
      "1.9984901256391303 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [49 | 150]\n",
      "1.9982694843618989 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [50 | 150]\n",
      "1.997707195502332 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [51 | 150]\n",
      "1.9968599267345946 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [52 | 150]\n",
      "1.9987819415713939 tensor(27.0777, device='cuda:0')\n",
      "\n",
      "Epoch: [53 | 150]\n",
      "1.9977505008511567 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [54 | 150]\n",
      "1.9984336053236798 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [55 | 150]\n",
      "1.998250225010932 tensor(27.0854, device='cuda:0')\n",
      "\n",
      "Epoch: [56 | 150]\n",
      "1.9979467861609697 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [57 | 150]\n",
      "1.999661752807092 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [58 | 150]\n",
      "1.9970403239557892 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [59 | 150]\n",
      "1.9982057357181653 tensor(27.0901, device='cuda:0')\n",
      "\n",
      "Epoch: [60 | 150]\n",
      "1.9981840005139615 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [61 | 150]\n",
      "1.9992042488817403 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [62 | 150]\n",
      "1.9966814920543485 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [63 | 150]\n",
      "1.9986881915303436 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [64 | 150]\n",
      "1.9980935560041706 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [65 | 150]\n",
      "1.9974811416590155 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [66 | 150]\n",
      "1.9983551844535397 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [67 | 150]\n",
      "1.9979512601815121 tensor(27.0746, device='cuda:0')\n",
      "\n",
      "Epoch: [68 | 150]\n",
      "1.9980949270352784 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [69 | 150]\n",
      "1.9981470039651714 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [70 | 150]\n",
      "1.997760842363352 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [71 | 150]\n",
      "1.9983888089685369 tensor(27.1101, device='cuda:0')\n",
      "\n",
      "Epoch: [72 | 150]\n",
      "1.9978394753235487 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [73 | 150]\n",
      "1.997122090190586 tensor(27.0901, device='cuda:0')\n",
      "\n",
      "Epoch: [74 | 150]\n",
      "1.9982948589816907 tensor(27.0792, device='cuda:0')\n",
      "\n",
      "Epoch: [75 | 150]\n",
      "1.997599666565323 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [76 | 150]\n",
      "1.9968265082320003 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [77 | 150]\n",
      "1.9983333937016772 tensor(27.0669, device='cuda:0')\n",
      "\n",
      "Epoch: [78 | 150]\n",
      "1.9989497933694935 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [79 | 150]\n",
      "1.9994384123592013 tensor(27.0777, device='cuda:0')\n",
      "\n",
      "Epoch: [80 | 150]\n",
      "1.9976065372712606 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [81 | 150]\n",
      "1.9987691211993552 tensor(27.0623, device='cuda:0')\n",
      "\n",
      "Epoch: [82 | 150]\n",
      "1.9983404434084264 tensor(27.0870, device='cuda:0')\n",
      "\n",
      "Epoch: [83 | 150]\n",
      "1.998476874961454 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [84 | 150]\n",
      "1.998437881298499 tensor(27.0808, device='cuda:0')\n",
      "\n",
      "Epoch: [85 | 150]\n",
      "1.9976241672622863 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [86 | 150]\n",
      "1.9993454236929902 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [87 | 150]\n",
      "1.9989838917592295 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [88 | 150]\n",
      "1.9979610599226802 tensor(27.0298, device='cuda:0')\n",
      "\n",
      "Epoch: [89 | 150]\n",
      "1.9986070708543457 tensor(27.0870, device='cuda:0')\n",
      "\n",
      "Epoch: [90 | 150]\n",
      "1.9982354466382337 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [91 | 150]\n",
      "1.9981179232726012 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [92 | 150]\n",
      "1.9974404187442318 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [93 | 150]\n",
      "1.997491272962815 tensor(27.0792, device='cuda:0')\n",
      "\n",
      "Epoch: [94 | 150]\n",
      "1.9974453663228349 tensor(27.1101, device='cuda:0')\n",
      "\n",
      "Epoch: [95 | 150]\n",
      "1.997470085329278 tensor(27.0916, device='cuda:0')\n",
      "\n",
      "Epoch: [96 | 150]\n",
      "1.9987683014727773 tensor(27.1055, device='cuda:0')\n",
      "\n",
      "Epoch: [97 | 150]\n",
      "1.9972135626653142 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [98 | 150]\n",
      "1.9976591309416731 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [99 | 150]\n",
      "1.9978842353526953 tensor(27.0638, device='cuda:0')\n",
      "\n",
      "Epoch: [100 | 150]\n",
      "1.997899636982277 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [101 | 150]\n",
      "1.9978392945515455 tensor(27.0746, device='cuda:0')\n",
      "\n",
      "Epoch: [102 | 150]\n",
      "1.997707560054786 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [103 | 150]\n",
      "1.9970757741881113 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [104 | 150]\n",
      "1.9966710025924277 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [105 | 150]\n",
      "1.9981953036542646 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [106 | 150]\n",
      "1.9979452470471017 tensor(27.1024, device='cuda:0')\n",
      "\n",
      "Epoch: [107 | 150]\n",
      "1.9987398486399792 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [108 | 150]\n",
      "1.9996990537062365 tensor(27.0669, device='cuda:0')\n",
      "\n",
      "Epoch: [109 | 150]\n",
      "1.9977414912860223 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [110 | 150]\n",
      "1.997596650469218 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [111 | 150]\n",
      "1.9986481975676524 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [112 | 150]\n",
      "1.9982772727475648 tensor(27.0808, device='cuda:0')\n",
      "\n",
      "Epoch: [113 | 150]\n",
      "1.998215490165069 tensor(27.0746, device='cuda:0')\n",
      "\n",
      "Epoch: [114 | 150]\n",
      "1.9978025571637914 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [115 | 150]\n",
      "1.9986553168277297 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [116 | 150]\n",
      "1.9983182040461591 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [117 | 150]\n",
      "1.998380307569661 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [118 | 150]\n",
      "1.9979223803203332 tensor(27.0993, device='cuda:0')\n",
      "\n",
      "Epoch: [119 | 150]\n",
      "1.9986675637406155 tensor(27.0700, device='cuda:0')\n",
      "\n",
      "Epoch: [120 | 150]\n",
      "1.9978151852326709 tensor(27.0931, device='cuda:0')\n",
      "\n",
      "Epoch: [121 | 150]\n",
      "1.9986963888900202 tensor(27.1148, device='cuda:0')\n",
      "\n",
      "Epoch: [122 | 150]\n",
      "1.9988429866385835 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [123 | 150]\n",
      "1.9982919755942268 tensor(27.0808, device='cuda:0')\n",
      "\n",
      "Epoch: [124 | 150]\n",
      "1.9982789649792814 tensor(27.0901, device='cuda:0')\n",
      "\n",
      "Epoch: [125 | 150]\n",
      "1.9972658965118748 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [126 | 150]\n",
      "1.9976547789860521 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [127 | 150]\n",
      "1.9976051159802923 tensor(27.1086, device='cuda:0')\n",
      "\n",
      "Epoch: [128 | 150]\n",
      "1.9977554873075976 tensor(27.0947, device='cuda:0')\n",
      "\n",
      "Epoch: [129 | 150]\n",
      "1.9978252963684537 tensor(27.0360, device='cuda:0')\n",
      "\n",
      "Epoch: [130 | 150]\n",
      "1.9970111626390232 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [131 | 150]\n",
      "1.9991323214169239 tensor(27.0746, device='cuda:0')\n",
      "\n",
      "Epoch: [132 | 150]\n",
      "1.9983187321944775 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [133 | 150]\n",
      "1.9982303018203336 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [134 | 150]\n",
      "1.9977346727216059 tensor(27.0885, device='cuda:0')\n",
      "\n",
      "Epoch: [135 | 150]\n",
      "1.997720508241675 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [136 | 150]\n",
      "1.9983433915953552 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [137 | 150]\n",
      "1.997409906474158 tensor(27.0453, device='cuda:0')\n",
      "\n",
      "Epoch: [138 | 150]\n",
      "1.998789596578238 tensor(27.0746, device='cuda:0')\n",
      "\n",
      "Epoch: [139 | 150]\n",
      "1.997581188075984 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [140 | 150]\n",
      "1.9992525879494654 tensor(27.1040, device='cuda:0')\n",
      "\n",
      "Epoch: [141 | 150]\n",
      "1.9996225493058133 tensor(27.0839, device='cuda:0')\n",
      "\n",
      "Epoch: [142 | 150]\n",
      "1.998318539675903 tensor(27.1009, device='cuda:0')\n",
      "\n",
      "Epoch: [143 | 150]\n",
      "1.9975465678899156 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [144 | 150]\n",
      "1.9986867694495196 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [145 | 150]\n",
      "1.99828140101385 tensor(26.9974, device='cuda:0')\n",
      "\n",
      "Epoch: [146 | 150]\n",
      "1.997426521412269 tensor(27.0962, device='cuda:0')\n",
      "\n",
      "Epoch: [147 | 150]\n",
      "1.9995101805788038 tensor(27.0762, device='cuda:0')\n",
      "\n",
      "Epoch: [148 | 150]\n",
      "1.999384425574863 tensor(27.0978, device='cuda:0')\n",
      "\n",
      "Epoch: [149 | 150]\n",
      "1.9976489927298586 tensor(27.0870, device='cuda:0')\n",
      "\n",
      "Epoch: [150 | 150]\n",
      "1.9979461012842967 tensor(27.0870, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "input_size = dataset.length\n",
    "predict_size = 9\n",
    "\n",
    "#input_size = train_dataset.length\n",
    "#predict_size = train_dataset.num_class\n",
    "\n",
    "model = get_network(args.model_configuration, input_size,prediction_size=predict_size, dropout=args.dropout, use_conv2d=args.conv2d)\n",
    "model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), args.lr,\n",
    "                                 weight_decay=args.weight_decay)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=np.ceil(\n",
    "    args.epochs/20.).astype(int), verbose=args.verbose,  min_lr=1e-6, cooldown=np.ceil(args.epochs/40.).astype(int))\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "\n",
    "    print('\\nEpoch: [%d | %d]' % (epoch + 1, args.epochs))\n",
    "\n",
    "    # train for one epoch\n",
    "    train_loss, train_acc = train(dataloader, len(dataloader), model, criterion, optimizer, epoch, args, predict_size)\n",
    "    print(train_loss, train_acc)\n",
    "    #val_loss, prec1, res = validate(dataloader, len(dataloader), model, criterion, predict_size, args=args)\n",
    "\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    \n",
    "\n",
    "    #lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/segate/Bits/4-1/SOP_Kamlesh_sir/heart/ATCN-master/ppg.ipynb#Y121sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39;49msave(model, \u001b[39m'\u001b[39;49m\u001b[39m./model.sav\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m/media/segate/Linux_programs/PythonVenv/.virtualenvs/env1/lib/python3.10/site-packages/torch/serialization.py:379\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 379\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    380\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    381\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[0;32m/media/segate/Linux_programs/PythonVenv/.virtualenvs/env1/lib/python3.10/site-packages/torch/serialization.py:601\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[39m# given that we copy things around anyway, we might use storage.cpu()\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[39m# this means to that to get tensors serialized, you need to implement\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[39m# .cpu() on the underlying Storage\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[39mif\u001b[39;00m storage\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 601\u001b[0m     storage \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m    602\u001b[0m \u001b[39m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[1;32m    603\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n",
      "File \u001b[0;32m/media/segate/Linux_programs/PythonVenv/.virtualenvs/env1/lib/python3.10/site-packages/torch/storage.py:112\u001b[0m, in \u001b[0;36m_StorageBase.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_UntypedStorage(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msize())\u001b[39m.\u001b[39;49mcopy_(\u001b[39mself\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    113\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.save(model, './model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c76be22c44012077b6e31f15d28eccdbbb1c9916bfae7aaff63eb549681cdcf9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
